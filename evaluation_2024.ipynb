{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Output\n",
    "## Detection\n",
    "Output of the detection module of a volume:\n",
    "\n",
    "```\n",
    "[\n",
    "  [[zs1, ys1, xs1, ze1, ye1, xe1], obj_score1, class1_score1, class2_score1],\n",
    "  [[zs2, ys2, xs2, ze2, ye2, xe2], obj_score2, class1_score2, class2_score2],\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "In the format above, xs, ys, and zs represents starts of the bounding box, xe, ye and ze represents ends of the bounding box. \"obj_score\" represents the confidence of this bounding box, \"class1_score\" represents the probability of this bounding box as the first class (intracranial aneurysm in this challenge), and \"class2_score\" represents the probability of this bounding box as the second class (stenosis). Note that the sum of probabilities of two classes should be 1.\n",
    "\n",
    "When evaluating each class of detection, the output will be processed using the following code to adapt the detection metrics code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1.nii.gz': [('stenosis', [50, 50, 50, 150, 150, 150], 0.6), ('IA', [10, 10, 10, 80, 80, 80], 0.5)], '2.nii.gz': [('IA', [20, 20, 20, 70, 70, 70], 0.4), ('stenosis', [60, 60, 60, 120, 120, 120], 0.1)]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def convert_output_to_detection(output):\n",
    "    \"\"\"\n",
    "    Convert the output to the format of the detection.\n",
    "    :param output: {img_id: [bbox]}\n",
    "    :param wanted_class_num: 1 or 2\n",
    "    :return: {img_id: [(bbox, score)]}\n",
    "    \"\"\"\n",
    "    detection = {}\n",
    "    for img_id, bbox_list in output.items():\n",
    "        detection[img_id] = []\n",
    "        for bbox in bbox_list:\n",
    "            if bbox[2] >= bbox[3]:\n",
    "                class_name = 'IA'\n",
    "            else:\n",
    "                class_name = 'stenosis'\n",
    "            detection[img_id].append((class_name, bbox[0], bbox[1]))\n",
    "    return detection\n",
    "\n",
    "output = {\n",
    "    \"1.nii.gz\": [[[50, 50, 50, 150, 150, 150], 0.6, 0.1, 0.9], [[10, 10, 10, 80, 80, 80], 0.5, 0.8, 0.2]],  # Prediction for image 1\n",
    "    \"2.nii.gz\": [[[20, 20, 20, 70, 70, 70], 0.4, 0.7, 0.3], [[60, 60, 60, 120, 120, 120], 0.1, 0.4, 0.6]],  # Prediction for image 2\n",
    "}\n",
    "\n",
    "print(convert_output_to_detection(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "Output of the segmentation task should be **an array with the same size as the input image**, with label 1 as segmented lesion (no matter whether intracranial aneurysm or stenosis). Patches in successfully detected bounding boxes will be cropped and segmentation metrics and clinical metrics will be calculated within the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection Part\n",
    "Definitions of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using metrics from https://github.com/autonomousvision/kitti360Scripts/blob/master/kitti360scripts/evaluation/semantic_3d/evalDetection.py\n",
    "def box3dVolume(corners):\n",
    "    ''' corners: (8,3) no assumption on axis direction '''\n",
    "    a = np.sqrt(np.sum((corners[0,:] - corners[1,:])**2))\n",
    "    b = np.sqrt(np.sum((corners[1,:] - corners[2,:])**2))\n",
    "    c = np.sqrt(np.sum((corners[0,:] - corners[4,:])**2))\n",
    "    return a*b*c\n",
    "\n",
    "\n",
    "def roty(t):\n",
    "    \"\"\"Rotation about the y-axis.\"\"\"\n",
    "    c = np.cos(t)\n",
    "    s = np.sin(t)\n",
    "    return np.array([[c,  0,  s],\n",
    "                    [0,  1,  0],\n",
    "                    [-s, 0,  c]])\n",
    "\n",
    "def rotz(t):\n",
    "    \"\"\"Rotation about the y-axis.\"\"\"\n",
    "    c = np.cos(t)\n",
    "    s = np.sin(t)\n",
    "    return np.array([[c,  -s,  0],\n",
    "                    [s,  c,  0],\n",
    "                    [0, 0,  1]])\n",
    "\n",
    "\n",
    "def vocAP(rec, prec, use_07_metric=False):\n",
    "    \"\"\" ap = vocAP(rec, prec, [use_07_metric])\n",
    "    Compute VOC AP given precision and recall.\n",
    "    If use_07_metric is true, uses the\n",
    "    VOC 07 11 point method (default:False).\n",
    "    \"\"\"\n",
    "    if use_07_metric:\n",
    "        # 11 point metric\n",
    "        ap = 0.\n",
    "        for t in np.arange(0., 1.1, 0.1):\n",
    "            if np.sum(rec >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(prec[rec >= t])\n",
    "            ap = ap + p / 11.\n",
    "    else:\n",
    "        # correct AP calculation\n",
    "        # first append sentinel values at the end\n",
    "        mrec = np.concatenate(([0.], rec, [1.]))\n",
    "        mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "        # compute the precision envelope\n",
    "        for i in range(mpre.size - 1, 0, -1):\n",
    "            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "        # to calculate area under PR curve, look for points\n",
    "        # where X axis (recall) changes value\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "        # and sum (\\Delta recall) * prec\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n",
    "\n",
    "\n",
    "def get3dIoU(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two 3D bounding boxes.\n",
    "    box1 and box2 should be in the format [x1, y1, z1, x2, y2, z2]\n",
    "    \"\"\"\n",
    "    x1_inter = max(box1[0], box2[0])\n",
    "    y1_inter = max(box1[1], box2[1])\n",
    "    z1_inter = max(box1[2], box2[2])\n",
    "    x2_inter = min(box1[3], box2[3])\n",
    "    y2_inter = min(box1[4], box2[4])\n",
    "    z2_inter = min(box1[5], box2[5])\n",
    "\n",
    "    if x1_inter < x2_inter and y1_inter < y2_inter and z1_inter < z2_inter:\n",
    "        inter_volume = (x2_inter - x1_inter) * (y2_inter - y1_inter) * (z2_inter - z1_inter)\n",
    "    else:\n",
    "        inter_volume = 0\n",
    "\n",
    "    box1_volume = (box1[3] - box1[0]) * (box1[4] - box1[1]) * (box1[5] - box1[2])\n",
    "    box2_volume = (box2[3] - box2[0]) * (box2[4] - box2[1]) * (box2[5] - box2[2])\n",
    "\n",
    "    iou_value = inter_volume / (box1_volume + box2_volume - inter_volume)\n",
    "    return iou_value\n",
    "\n",
    "def evalDetectionClass(pred, gt, ovthresh=0.25, use_07_metric=False):\n",
    "    \"\"\" Generic functions to compute precision/recall for object detection\n",
    "        for a single class.\n",
    "        Input:\n",
    "            pred: map of {img_id: [(bbox, score)]} where bbox is numpy array\n",
    "            gt: map of {img_id: [bbox]}\n",
    "            ovthresh: scalar, iou threshold\n",
    "            use_07_metric: bool, if True use VOC07 11 point method\n",
    "        Output:\n",
    "            rec: numpy array of length nd\n",
    "            prec: numpy array of length nd\n",
    "            ap: scalar, average precision\n",
    "    \"\"\"\n",
    "\n",
    "    # construct gt objects\n",
    "    class_recs = {} # {img_id: {'bbox': bbox list, 'det': matched list}}\n",
    "    npos = 0\n",
    "    for img_id in gt.keys():\n",
    "        bbox = np.array(gt[img_id])\n",
    "        det = [False] * len(bbox)\n",
    "        npos += len(bbox)\n",
    "        class_recs[img_id] = {'bbox': bbox, 'det': det}\n",
    "\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # from mpl_toolkits.mplot3d import Axes3D\n",
    "        # fig = plt.figure()\n",
    "        # ax = fig.add_subplot(111, projection='3d')\n",
    "        # for bbox_ in bbox:\n",
    "        #     ax.plot(*bbox_.T,'.')\n",
    "        # ax.set_zlim3d([0,200])\n",
    "        # plt.show()\n",
    "    # pad empty list to all other imgids\n",
    "    for img_id in pred.keys():\n",
    "        if img_id not in gt:\n",
    "            class_recs[img_id] = {'bbox': np.array([]), 'det': []}\n",
    "\n",
    "    # construct dets\n",
    "    image_ids = []\n",
    "    confidence = []\n",
    "    BB = []\n",
    "    for img_id in pred.keys():\n",
    "        for box,score in pred[img_id]:\n",
    "            image_ids.append(img_id)\n",
    "            confidence.append(score)\n",
    "            BB.append(box)\n",
    "    confidence = np.array(confidence)\n",
    "    BB = np.array(BB) # (nd,4 or 8,3 or 6)\n",
    "\n",
    "    # sort by confidence\n",
    "    sorted_ind = np.argsort(-confidence, kind=\"stable\")  # the stable sort method is used to keep the order of the boxes with the same confidence\n",
    "    sorted_scores = np.sort(-confidence, kind=\"stable\")\n",
    "    BB = BB[sorted_ind, ...]\n",
    "    image_ids = [image_ids[x] for x in sorted_ind]\n",
    "\n",
    "    # go down dets and mark TPs and FPs\n",
    "    nd = len(image_ids)\n",
    "    tp = np.zeros(nd)\n",
    "    fp = np.zeros(nd)\n",
    "    for d in range(nd):\n",
    "        R = class_recs[image_ids[d]]\n",
    "        bb = BB[d,...].astype(float)\n",
    "        ovmax = -np.inf\n",
    "        BBGT = R['bbox'].astype(float)\n",
    "\n",
    "        if BBGT.size > 0:\n",
    "            # compute overlaps\n",
    "            for j in range(BBGT.shape[0]):\n",
    "                iou = get3dIoU(bb, BBGT[j,...])\n",
    "                if iou > ovmax:\n",
    "                    ovmax = iou\n",
    "                    jmax = j\n",
    "\n",
    "        if ovmax > ovthresh:\n",
    "            if not R['det'][jmax]:\n",
    "                tp[d] = 1.\n",
    "                R['det'][jmax] = 1\n",
    "            else:\n",
    "                fp[d] = 1.\n",
    "        else:\n",
    "            fp[d] = 1.\n",
    "\n",
    "    # compute precision recall\n",
    "    fp = np.cumsum(fp)\n",
    "    tp = np.cumsum(tp)\n",
    "    rec = tp / float(npos)\n",
    "    # avoid divide by zero in case the first detection matches a difficult\n",
    "    # ground truth\n",
    "    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "    ap = vocAP(rec, prec, use_07_metric)\n",
    "\n",
    "    return rec, prec, ap\n",
    "\n",
    "def evalDetectionClassWrapper(arguments):\n",
    "    pred, gt, ovthresh, use_07_metric = arguments\n",
    "    rec, prec, ap = evalDetectionClass(pred, gt, ovthresh, use_07_metric)\n",
    "    return (rec, prec, ap)\n",
    "\n",
    "def evalDetection(pred_all, gt_all, ovthresh=0.25, use_07_metric=False):\n",
    "    \"\"\" Generic functions to compute precision/recall for object detection\n",
    "        for multiple classes.\n",
    "        Input:\n",
    "            pred_all: map of {img_id: [(classname, bbox, score)]}\n",
    "            gt_all: map of {img_id: [(classname, bbox)]}\n",
    "            ovthresh: scalar, iou threshold\n",
    "            use_07_metric: bool, if true use VOC07 11 point method\n",
    "        Output:\n",
    "            rec: {classname: rec}\n",
    "            prec: {classname: prec_all}\n",
    "            ap: {classname: scalar}\n",
    "    \"\"\"\n",
    "    pred = {} # map {classname: pred}\n",
    "    gt = {} # map {classname: gt}\n",
    "    for img_id in pred_all.keys():\n",
    "        for classname, bbox, score in pred_all[img_id]:\n",
    "            if classname not in pred: pred[classname] = {}\n",
    "            if img_id not in pred[classname]:\n",
    "                pred[classname][img_id] = []\n",
    "            if classname not in gt: gt[classname] = {}\n",
    "            if img_id not in gt[classname]:\n",
    "                gt[classname][img_id] = []\n",
    "            pred[classname][img_id].append((bbox,score))\n",
    "    for img_id in gt_all.keys():\n",
    "        for classname, bbox in gt_all[img_id]:\n",
    "            if classname not in gt: gt[classname] = {}\n",
    "            if img_id not in gt[classname]:\n",
    "                gt[classname][img_id] = []\n",
    "            gt[classname][img_id].append(bbox)\n",
    "\n",
    "    rec = {}\n",
    "    prec = {}\n",
    "    ap = {}\n",
    "    for classname in gt.keys():\n",
    "        print('Computing AP for class: ', classname)\n",
    "        rec[classname], prec[classname], ap[classname] = evalDetectionClass(pred[classname], gt[classname], ovthresh, use_07_metric)\n",
    "        print(classname, ap[classname])\n",
    "\n",
    "    return rec, prec, ap\n",
    "\n",
    "def convert_gt_to_detection(gt):\n",
    "    \"\"\"\n",
    "    Convert the ground truth to the format of the detection.\n",
    "    :param gt: {img_id: [[bbox, class_num]]}\n",
    "    :return: {img_id: [(classname, bbox)]}\n",
    "    \"\"\"\n",
    "    detection = {}\n",
    "    for img_id, bbox_list in gt.items():\n",
    "        detection[img_id] = []\n",
    "        for bbox in bbox_list:\n",
    "            if bbox[1] == 1:\n",
    "                class_name = 'IA'\n",
    "            elif bbox[1] == 2:\n",
    "                class_name = 'stenosis'\n",
    "            detection[img_id].append((class_name, bbox[0]))\n",
    "    return detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing AP for class:  IA\n",
      "IA 1.0\n",
      "Computing AP for class:  IA\n",
      "IA 0.5694444444444444\n",
      "0.7847222222222222\n"
     ]
    }
   ],
   "source": [
    "predictions_IA = {  # Predictions for each image in the ENTIRE test set / validation set / training set of ONE class, e.g. aneurysm\n",
    "    \"1.nii.gz\": [([50, 50, 50, 150, 150, 150], 0.6, 0.9, 0.1), ([10, 10, 10, 80, 80, 80], 0.5, 0.9, 0.1)],  # Prediction for image 1\n",
    "    \"2.nii.gz\": [([20, 20, 20, 70, 70, 70], 0.4, 0.9, 0.1), ([60, 60, 60, 120, 120, 120], 0.1, 0.9, 0.1)],  # Prediction for image 2\n",
    "    \"3.nii.gz\": [([40, 40, 40, 160, 160, 160], 0.7, 0.9, 0.1), ([35, 35, 35, 105, 105, 105], 0.2, 0.9, 0.1)],  # Prediction for image 3\n",
    "}\n",
    "ground_truths_IA = {  # Ground truths for each image in the ENTIRE test set / validation set / training set of ONE class, e.g. aneurysm\n",
    "    \"1.nii.gz\": [[[40, 40, 40, 160, 160, 160], 1], [[35, 35, 35, 105, 105, 105], 1]],  # Ground truth for image 1\n",
    "    \"2.nii.gz\": [[[15, 15, 15, 75, 75, 75], 1], [[65, 65, 65, 130, 130, 130], 1]],  # Ground truth for image 2\n",
    "    \"3.nii.gz\": [[[50, 50, 50, 150, 150, 150], 1], [[10, 10, 10, 80, 80, 80], 1]],  # Ground truth for image 3\n",
    "}\n",
    "\n",
    "bbox_pred = convert_output_to_detection(predictions_IA)\n",
    "bbox_gt = convert_gt_to_detection(ground_truths_IA)\n",
    "\n",
    "_, _, ap15 = evalDetection(bbox_pred, bbox_gt, ovthresh=0.15, use_07_metric=False)\n",
    "_, _, ap25 = evalDetection(bbox_pred, bbox_gt, ovthresh=0.25, use_07_metric=False)\n",
    "ap15_IA = ap15[\"IA\"]\n",
    "ap25_IA = ap25[\"IA\"]\n",
    "\n",
    "ap_IA = (ap15_IA + ap25_IA) / 2\n",
    "\n",
    "print(ap_IA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Part\n",
    "Definition of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from medpy.metric.binary import hd95\n",
    "\n",
    "def dice_score(pred, gt):\n",
    "    \"\"\"\n",
    "    Calculate Dice score between two binary masks\n",
    "    \"\"\"\n",
    "    pred = np.bool_(pred)\n",
    "    gt = np.bool_(gt)\n",
    "    intersection = np.count_nonzero(pred & gt)\n",
    "    union = np.count_nonzero(pred | gt)\n",
    "    dice = 2 * intersection / (np.count_nonzero(pred) + np.count_nonzero(gt))\n",
    "    return dice\n",
    "\n",
    "def hausdorff_distance_unified(pred, gt, baseline, voxel_spacing):\n",
    "    \"\"\"\n",
    "    Calculate Hausdorff distance between two binary masks, then unify the result to (0-1) with a baseline\n",
    "    \"\"\"\n",
    "    pred = np.bool_(pred)\n",
    "    gt = np.bool_(gt)\n",
    "    hd = hd95(pred, gt, voxel_spacing)\n",
    "    hd_baseline = hd95(baseline, gt, voxel_spacing)\n",
    "    hd = 1 - hd / hd_baseline\n",
    "    if hd < 0:\n",
    "        hd = 0\n",
    "    return hd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice: 0.5673352435530086, HD: 0.38350379760491016\n"
     ]
    }
   ],
   "source": [
    "# each metric of one type of lesion is calculated for each lesion (i.e. each bounding box), then averaged across all lesions\n",
    "dice_scores = []\n",
    "hd_scores = []\n",
    "\n",
    "# Example: 160*200*200 image, spacing is (0.8, 0.6, 0.6), lesion ground-truth bounding box at [x1, y1, z1, x2, y2, z2] = [30, 30, 30, 50, 50, 50]\n",
    "# Note that a predicted bounding box with IoU > 0.15 and any positive probability is considered a true positive\n",
    "label_img = np.zeros((160, 200, 200))\n",
    "label_img[30:50, 30:50, 30:50] = 1\n",
    "pred_img = np.zeros((160, 200, 200))\n",
    "pred_img[32:48, 31:49, 34:45] = 1\n",
    "baseline_pred_img = np.zeros((160, 200, 200))  # baseline prediction made by simple thresholding\n",
    "baseline_pred_img[33:47, 32:48, 36:42] = 1\n",
    "spacing = (0.8, 0.6, 0.6)\n",
    "\n",
    "bbox_gt = [30, 30, 30, 50, 50, 50]\n",
    "\n",
    "pred_img_in_bbox = pred_img[bbox_gt[0]:bbox_gt[3], bbox_gt[1]:bbox_gt[4], bbox_gt[2]:bbox_gt[5]]\n",
    "label_img_in_bbox = label_img[bbox_gt[0]:bbox_gt[3], bbox_gt[1]:bbox_gt[4], bbox_gt[2]:bbox_gt[5]]\n",
    "baseline_pred_img_in_bbox = baseline_pred_img[bbox_gt[0]:bbox_gt[3], bbox_gt[1]:bbox_gt[4], bbox_gt[2]:bbox_gt[5]]\n",
    "\n",
    "dice = dice_score(pred_img_in_bbox, label_img_in_bbox)\n",
    "hd = hausdorff_distance_unified(pred_img_in_bbox, label_img_in_bbox, baseline_pred_img_in_bbox, spacing)\n",
    "dice_scores.append(dice)\n",
    "hd_scores.append(hd)\n",
    "\n",
    "total_dice = np.mean(dice_scores)\n",
    "total_hd = np.mean(hd_scores)\n",
    "\n",
    "print(f'Dice: {total_dice}, HD: {total_hd}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Part\n",
    "## Stenosis percentage\n",
    "Definition of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, measure, morphology\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "def get_max_connective_field(cube):\n",
    "    if np.sum(cube) == 0:\n",
    "        return cube\n",
    "    result = measure.label(cube)\n",
    "    result1 = result.reshape([-1])\n",
    "    lst = np.bincount(result1)\n",
    "    lst[0] = 0\n",
    "    a = np.argmax(lst)\n",
    "    result[result != a] = 0\n",
    "    result[result == a] = 1\n",
    "    return result\n",
    "\n",
    "def max_and_min_diameters(segmentation_image, spacing):\n",
    "    \"\"\"\n",
    "    :param segmentation_image: Binary segmentation image with the vessel as 1 and background as 0.\n",
    "    \"\"\"\n",
    "    binary_image = segmentation_image > 0\n",
    "    binary_image = get_max_connective_field(binary_image)  # The max connective field of the segmentation result is picked\n",
    "    skeleton = morphology.skeletonize(binary_image)\n",
    "    distance_transform = distance_transform_edt(binary_image, sampling=spacing)\n",
    "\n",
    "    # Get the coordinates of the skeleton\n",
    "    skeleton_coords = np.column_stack(np.where(skeleton))\n",
    "\n",
    "    # Calculate the diameter at each point in the skeleton\n",
    "    diameters = [2 * distance_transform[tuple(coord)] for coord in skeleton_coords]\n",
    "\n",
    "    return np.max(diameters), np.min(diameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth vessel percentage: 0.45943752238266466, Predicted vessel percentage: 0.6581182706210862, Difference: 0.19868074823842152\n"
     ]
    }
   ],
   "source": [
    "from skimage.morphology import disk\n",
    "\n",
    "def generate_example_image(disk_radii):\n",
    "    image = np.zeros([len(disk_radii), 50, 50])\n",
    "    for i, radius in enumerate(disk_radii):\n",
    "        image[i, 25 - radius:25 + radius + 1, 25 - radius:25 + radius + 1] = disk(radius)\n",
    "\n",
    "    return image\n",
    "\n",
    "spacing = (0.8, 0.6, 0.6)\n",
    "\n",
    "gt_label = generate_example_image([5, 5, 5, 4, 3, 2, 3, 4, 5, 5, 5])  # diameter of ordinary vessel is 9 and stenosis is 5\n",
    "pred_label = generate_example_image([4, 3, 2, 1, 2, 3, 4])  # predicted diameter of ordinary vessel is 9 and stenosis is 3\n",
    "gt_max, gt_min = max_and_min_diameters(gt_label, spacing)  # note that we have labelled the ordinary vessel beside the stenosis site in our test set GT using another label, so we can calculate the diameter of the ordinary vessel\n",
    "_, pred_min = max_and_min_diameters(pred_label, spacing)\n",
    "gt_percentage = (gt_max - gt_min) / gt_max\n",
    "pred_percentage = (gt_max - pred_min) / gt_max\n",
    "print(f'Ground truth vessel percentage: {gt_percentage}, Predicted vessel percentage: {pred_percentage}, Difference: {abs(gt_percentage - pred_percentage)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final score of this part is _1 - Difference_. Values lower than 0 will be set to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aneurysm long and short axes length\n",
    "Definition of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from skimage import measure\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np\n",
    "\n",
    "def max_diameter_short_radius(arr):\n",
    "    flat_arr = np.ravel(arr)\n",
    "    indices = np.where(flat_arr == 1)[0]\n",
    "    coordinates = np.column_stack(np.unravel_index(indices, arr.shape))\n",
    "    distances = squareform(pdist(coordinates))\n",
    "    i, j = np.unravel_index(np.argmax(distances), distances.shape)\n",
    "    max_diameter = distances[i, j]\n",
    "    midpoint = (coordinates[i] + coordinates[j]) / 2\n",
    "    vector = coordinates[j] - coordinates[i]\n",
    "    perp_vector = np.array([-vector[1], vector[0]])\n",
    "    k = np.argmax(np.abs(np.dot(coordinates - midpoint, perp_vector)))\n",
    "    l = np.argmin(np.abs(np.dot(coordinates - midpoint, perp_vector)))\n",
    "    short_radius = np.linalg.norm(coordinates[k] - coordinates[l])\n",
    "    return max_diameter, short_radius\n",
    "\n",
    "def get_2d_diameters(label_arr,nodule_spacing):\n",
    "    mask = label_arr\n",
    "    mask = get_max_connective_field(mask)  # The max connective field of the segmentation result is picked\n",
    "    largest_z = np.argmax(np.sum(mask, axis=(1,2)))\n",
    "    lag_z = mask[largest_z]\n",
    "    max_diameter, short_diameter =max_diameter_short_radius(lag_z)\n",
    "    return max_diameter*nodule_spacing[1],short_diameter*nodule_spacing[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth max diameter: 6.0, Predicted max diameter: 4.8, NMAE: 0.20000000000000004\n",
      "Ground truth short diameter: 4.242640687119285, Predicted short diameter: 3.394112549695428, NMAE: 0.19999999999999993\n"
     ]
    }
   ],
   "source": [
    "from skimage.morphology import ball\n",
    "import numpy as np\n",
    "\n",
    "def generate_example_image(disk_radius):\n",
    "    i = np.zeros([100, 100, 100])\n",
    "    b = ball(disk_radius)\n",
    "    i[50:50 + b.shape[0], 50:50 + b.shape[1], 50:50 + b.shape[2]] = b\n",
    "    return i\n",
    "\n",
    "spacing = (0.8, 0.6, 0.6)\n",
    "\n",
    "gt_label = generate_example_image(5)\n",
    "pred_label = generate_example_image(4)\n",
    "bbox = [50, 50, 50, 50 + 2 * 5 + 1, 50 + 2 * 5 + 1, 50 + 2 * 5 + 1]\n",
    "\n",
    "gt_label_in_bbox = gt_label[bbox[0]:bbox[3], bbox[1]:bbox[4], bbox[2]:bbox[5]]\n",
    "pred_label_in_bbox = pred_label[bbox[0]:bbox[3], bbox[1]:bbox[4], bbox[2]:bbox[5]]\n",
    "\n",
    "gt_max_diameter, gt_short_diameter = get_2d_diameters(gt_label, spacing)\n",
    "pred_max_diameter, pred_short_diameter = get_2d_diameters(pred_label, spacing)\n",
    "print(f'Ground truth max diameter: {gt_max_diameter}, Predicted max diameter: {pred_max_diameter}, NMAE: {abs(gt_max_diameter - pred_max_diameter) / gt_max_diameter}')\n",
    "print(f'Ground truth short diameter: {gt_short_diameter}, Predicted short diameter: {pred_short_diameter}, NMAE: {abs(gt_short_diameter - pred_short_diameter) / gt_short_diameter}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final score of this part is _1 - NMAE_. Values lower than 0 will be set to 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "link",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
